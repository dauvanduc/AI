{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dauvanduc/AI/blob/main/H%E1%BB%8Dc_m%C3%A1y_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrXfSMV-sCfO"
      },
      "source": [
        "# Chương 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5rLewcusCfR"
      },
      "source": [
        "# 3.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UJtDoTOrsCfS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "dataframe = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT7Q8lkEsCfT",
        "outputId": "38048446-cdaf-4d1a-9c0d-b3cb00a72abd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "\n",
            "   Parch     Ticket     Fare Cabin Embarked  \n",
            "0      0  A/5 21171   7.2500   NaN        S  \n",
            "1      0   PC 17599  71.2833   C85        C  \n",
            "Demensions: (891, 12)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>714.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.383838</td>\n",
              "      <td>2.308642</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.523008</td>\n",
              "      <td>0.381594</td>\n",
              "      <td>32.204208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>257.353842</td>\n",
              "      <td>0.486592</td>\n",
              "      <td>0.836071</td>\n",
              "      <td>14.526497</td>\n",
              "      <td>1.102743</td>\n",
              "      <td>0.806057</td>\n",
              "      <td>49.693429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>223.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>20.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.910400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>668.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
              "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
              "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
              "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
              "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
              "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
              "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
              "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
              "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
              "\n",
              "            Parch        Fare  \n",
              "count  891.000000  891.000000  \n",
              "mean     0.381594   32.204208  \n",
              "std      0.806057   49.693429  \n",
              "min      0.000000    0.000000  \n",
              "25%      0.000000    7.910400  \n",
              "50%      0.000000   14.454200  \n",
              "75%      0.000000   31.000000  \n",
              "max      6.000000  512.329200  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = \"titanic.csv\"\n",
        "df = pd.read_csv(url)\n",
        "#show fist two rows\n",
        "print(df.head(2)) #also try tail(2) for last two rows\n",
        "#show dimensions\n",
        "print(\"Demensions: {}\".format(df.shape))\n",
        "#show startistics\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noue5waesCfU",
        "outputId": "5628b027-588c-42f2-d66a-b22d0314bad0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>Driver</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jacky Jackson</td>\n",
              "      <td>38</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Steven Stevenson</td>\n",
              "      <td>25</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Name  Age  Driver\n",
              "0     Jacky Jackson   38    True\n",
              "1  Steven Stevenson   25   False"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load library\n",
        "import pandas as pd\n",
        "# Create DataFrame\n",
        "dataframe = pd.DataFrame()\n",
        "# Add columns\n",
        "dataframe['Name'] = ['Jacky Jackson', 'Steven Stevenson']\n",
        "dataframe['Age'] = [38, 25]\n",
        "dataframe['Driver'] = [True, False]\n",
        "# Show DataFrame\n",
        "dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1mmXWPQsCfV",
        "outputId": "c59c91ea-d3d3-4305-a95d-ea350faf9a9e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>Driver</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jacky Jackson</td>\n",
              "      <td>38</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Steven Stevenson</td>\n",
              "      <td>25</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Molly Mooney</td>\n",
              "      <td>40</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Name  Age  Driver\n",
              "0     Jacky Jackson   38    True\n",
              "1  Steven Stevenson   25   False\n",
              "2      Molly Mooney   40    True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create row\n",
        "new_person = pd.Series(['Molly Mooney', 40, True], index=['Name','Age','Driver'])\n",
        "# Append row\n",
        "dataframe.append(new_person, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyqj9afOsCfV",
        "outputId": "e481d440-ad1a-4d01-d2c7-8df4bf63d35a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "\n",
              "   Parch     Ticket     Fare Cabin Embarked  \n",
              "0      0  A/5 21171   7.2500   NaN        S  \n",
              "1      0   PC 17599  71.2833   C85        C  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = \"titanic.csv\"\n",
        "# Load data\n",
        "dataframe = pd.read_csv(url)\n",
        "# Show two rows\n",
        "dataframe.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Nfwfy2ksCfX",
        "outputId": "9b1ee9bd-144a-4748-9e1a-b3ec34c8624f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(891, 12)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show dimensions\n",
        "dataframe.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIwQSuX_sCfX",
        "outputId": "ce49ae3f-4d83-4853-efaf-422cc877caab"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>714.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.383838</td>\n",
              "      <td>2.308642</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.523008</td>\n",
              "      <td>0.381594</td>\n",
              "      <td>32.204208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>257.353842</td>\n",
              "      <td>0.486592</td>\n",
              "      <td>0.836071</td>\n",
              "      <td>14.526497</td>\n",
              "      <td>1.102743</td>\n",
              "      <td>0.806057</td>\n",
              "      <td>49.693429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>223.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>20.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.910400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>668.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
              "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
              "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
              "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
              "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
              "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
              "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
              "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
              "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
              "\n",
              "            Parch        Fare  \n",
              "count  891.000000  891.000000  \n",
              "mean     0.381594   32.204208  \n",
              "std      0.806057   49.693429  \n",
              "min      0.000000    0.000000  \n",
              "25%      0.000000    7.910400  \n",
              "50%      0.000000   14.454200  \n",
              "75%      0.000000   31.000000  \n",
              "max      6.000000  512.329200  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show statistics\n",
        "dataframe.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O1a1dxXsCfY"
      },
      "source": [
        "# 3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-dyQ_QXsCfY",
        "outputId": "f7731baf-3c36-4333-e2ef-c82b5500ffac"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>PClass</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Survived</th>\n",
              "      <th>SexCode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Allen, Miss Elisabeth Walton</td>\n",
              "      <td>1st</td>\n",
              "      <td>29.00</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Allison, Miss Helen Loraine</td>\n",
              "      <td>1st</td>\n",
              "      <td>2.00</td>\n",
              "      <td>female</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
              "      <td>1st</td>\n",
              "      <td>30.00</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
              "      <td>1st</td>\n",
              "      <td>25.00</td>\n",
              "      <td>female</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Allison, Master Hudson Trevor</td>\n",
              "      <td>1st</td>\n",
              "      <td>0.92</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Name PClass    Age     Sex  \\\n",
              "0                   Allen, Miss Elisabeth Walton    1st  29.00  female   \n",
              "1                    Allison, Miss Helen Loraine    1st   2.00  female   \n",
              "2            Allison, Mr Hudson Joshua Creighton    1st  30.00    male   \n",
              "3  Allison, Mrs Hudson JC (Bessie Waldo Daniels)    1st  25.00  female   \n",
              "4                  Allison, Master Hudson Trevor    1st   0.92    male   \n",
              "\n",
              "   Survived  SexCode  \n",
              "0         1        1  \n",
              "1         0        1  \n",
              "2         0        0  \n",
              "3         0        1  \n",
              "4         1        0  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load library\n",
        "import pandas as pd\n",
        "# Create URL\n",
        "url = 'https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/titanic.csv'\n",
        "# Load data\n",
        "dataframe = pd.read_csv(url)\n",
        "# Show two rows\n",
        "dataframe.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27U8iM3PsCfZ",
        "outputId": "80066179-81de-462a-8dfe-9544d40c8d1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(891, 12)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load library\n",
        "import pandas as pd\n",
        "# Create URL\n",
        "url = 'titanic.csv'\n",
        "# Load data\n",
        "dataframe = pd.read_csv(url)\n",
        "# Show dimensions\n",
        "dataframe.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VroP9WVxsCfZ",
        "outputId": "1b6b8ca5-ae06-4f23-ab44-15bc5458be4a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>714.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.383838</td>\n",
              "      <td>2.308642</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.523008</td>\n",
              "      <td>0.381594</td>\n",
              "      <td>32.204208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>257.353842</td>\n",
              "      <td>0.486592</td>\n",
              "      <td>0.836071</td>\n",
              "      <td>14.526497</td>\n",
              "      <td>1.102743</td>\n",
              "      <td>0.806057</td>\n",
              "      <td>49.693429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>223.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>20.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.910400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>668.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
              "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
              "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
              "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
              "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
              "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
              "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
              "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
              "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
              "\n",
              "            Parch        Fare  \n",
              "count  891.000000  891.000000  \n",
              "mean     0.381594   32.204208  \n",
              "std      0.806057   49.693429  \n",
              "min      0.000000    0.000000  \n",
              "25%      0.000000    7.910400  \n",
              "50%      0.000000   14.454200  \n",
              "75%      0.000000   31.000000  \n",
              "max      6.000000  512.329200  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create URL\n",
        "url = 'titanic.csv'\n",
        "# Load data\n",
        "dataframe = pd.read_csv(url)\n",
        "# Show statistics\n",
        "dataframe.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hVnmK_PsCfa"
      },
      "source": [
        "# 3.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74nYTqREsCfa",
        "outputId": "81f63c8e-315c-47f9-8103-0f96ef4ea483"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PassengerId                          1\n",
              "Survived                             0\n",
              "Pclass                               3\n",
              "Name           Braund, Mr. Owen Harris\n",
              "Sex                               male\n",
              "Age                                 22\n",
              "SibSp                                1\n",
              "Parch                                0\n",
              "Ticket                       A/5 21171\n",
              "Fare                              7.25\n",
              "Cabin                              NaN\n",
              "Embarked                             S\n",
              "Name: 0, dtype: object"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load library\n",
        "import pandas as pd\n",
        "# Create URL\n",
        "url = 'titanic.csv'\n",
        "# Load data\n",
        "dataframe = pd.read_csv(url)\n",
        "# Select first row\n",
        "dataframe.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAKVC1RysCfa",
        "outputId": "e2f80cd3-296e-46ec-c699-c645bbcef914"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Select three rows\n",
        "dataframe.iloc[1:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8s22FL1jsCfb",
        "outputId": "c0034841-508c-4ab2-ac1a-824d3fbf5ffc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Select four rows\n",
        "dataframe.iloc[:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yueEmGqfsCfb",
        "outputId": "0b0126a1-1a16-4c80-b2e7-66fd1a4a6217"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PassengerId                          1\n",
              "Survived                             0\n",
              "Pclass                               3\n",
              "Name           Braund, Mr. Owen Harris\n",
              "Sex                               male\n",
              "Age                                 22\n",
              "SibSp                                1\n",
              "Parch                                0\n",
              "Ticket                       A/5 21171\n",
              "Fare                              7.25\n",
              "Cabin                              NaN\n",
              "Embarked                             S\n",
              "Name: Braund, Mr. Owen Harris, dtype: object"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set index\n",
        "dataframe = dataframe.set_index(dataframe['Name'])\n",
        "# Show row\n",
        "dataframe.loc['Braund, Mr. Owen Harris']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwmo6f0FsCfb"
      },
      "source": [
        "# 3.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXQWq8FbsCfc",
        "outputId": "38fb7f84-c74a-4bfe-e187-4ccb543ce3cd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>347742</td>\n",
              "      <td>11.1333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "8            9         1       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "8      2            347742  11.1333   NaN        S  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load library\n",
        "import pandas as pd\n",
        "# Create URL\n",
        "url = 'titanic.csv'\n",
        "# Load data\n",
        "dataframe = pd.read_csv(url)\n",
        "# Show top four rows where column 'sex' is 'female'\n",
        "dataframe[dataframe['Sex'] == 'female'].head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ap62YN0sCfc",
        "outputId": "ea49695e-896f-48c5-fb66-acb81adc52d7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>276</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Andrews, Miss. Kornelia Theodosia</td>\n",
              "      <td>female</td>\n",
              "      <td>63.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>13502</td>\n",
              "      <td>77.9583</td>\n",
              "      <td>D7</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>367</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Warren, Mrs. Frank Manley (Anna Sophia Atkinson)</td>\n",
              "      <td>female</td>\n",
              "      <td>60.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>110813</td>\n",
              "      <td>75.2500</td>\n",
              "      <td>D37</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>483</th>\n",
              "      <td>484</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Turkula, Mrs. (Hedwig)</td>\n",
              "      <td>female</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4134</td>\n",
              "      <td>9.5875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>830</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
              "      <td>female</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>113572</td>\n",
              "      <td>80.0000</td>\n",
              "      <td>B28</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  \\\n",
              "275          276         1       1   \n",
              "366          367         1       1   \n",
              "483          484         1       3   \n",
              "829          830         1       1   \n",
              "\n",
              "                                                 Name     Sex   Age  SibSp  \\\n",
              "275                 Andrews, Miss. Kornelia Theodosia  female  63.0      1   \n",
              "366  Warren, Mrs. Frank Manley (Anna Sophia Atkinson)  female  60.0      1   \n",
              "483                            Turkula, Mrs. (Hedwig)  female  63.0      0   \n",
              "829         Stone, Mrs. George Nelson (Martha Evelyn)  female  62.0      0   \n",
              "\n",
              "     Parch  Ticket     Fare Cabin Embarked  \n",
              "275      0   13502  77.9583    D7        S  \n",
              "366      0  110813  75.2500   D37        C  \n",
              "483      0    4134   9.5875   NaN        S  \n",
              "829      0  113572  80.0000   B28      NaN  "
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create URL\n",
        "url = 'titanic.csv'\n",
        "# Load data\n",
        "dataframe = pd.read_csv(url)\n",
        "# Filter rows\n",
        "dataframe[(dataframe['Sex'] == 'female') & (dataframe['Age'] >= 60)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwQLXg86sCfd"
      },
      "source": [
        "# 3.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5-YW6P9sCfd",
        "outputId": "197a210e-135d-41ef-9604-4f64ebae6642"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     male\n",
              "1    Woman\n",
              "2    Woman\n",
              "3    Woman\n",
              "4     male\n",
              "Name: Sex, dtype: object"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load library\n",
        "import pandas as pd\n",
        "# Create URL\n",
        "url = 'titanic.csv'\n",
        "# Load data\n",
        "dataframe = pd.read_csv(url)\n",
        "# Replace values, show two rows\n",
        "dataframe['Sex'].replace(\"female\", \"Woman\").head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_q7k57gsCfe",
        "outputId": "080d38bc-a61d-42a6-8a49-20ffc53385e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      Man\n",
              "1    Woman\n",
              "2    Woman\n",
              "3    Woman\n",
              "4      Man\n",
              "Name: Sex, dtype: object"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Replace \"female\" and \"male with \"Woman\" and \"Man\"\n",
        "dataframe['Sex'].replace([\"female\", \"male\"], [\"Woman\", \"Man\"]).head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yl5HXij5sCfe",
        "outputId": "42e52b2b-16e4-4b8e-bcbb-b3bf2dba98e5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22</td>\n",
              "      <td>One</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>One</td>\n",
              "      <td>One</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38</td>\n",
              "      <td>One</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  PassengerId Survived Pclass  \\\n",
              "0         One        0      3   \n",
              "1           2      One    One   \n",
              "\n",
              "                                                Name     Sex Age SibSp Parch  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22   One     0   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38   One     0   \n",
              "\n",
              "      Ticket     Fare Cabin Embarked  \n",
              "0  A/5 21171   7.2500   NaN        S  \n",
              "1   PC 17599  71.2833   C85        C  "
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Replace values, show two rows\n",
        "dataframe.replace(1, \"One\").head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOM5UcAGsCff",
        "outputId": "3b3bfa10-02a6-4015-b064-fb6c48791fbb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>PClass</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Survived</th>\n",
              "      <th>SexCode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Allen, Miss Elisabeth Walton</td>\n",
              "      <td>First</td>\n",
              "      <td>29.0</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Allison, Miss Helen Loraine</td>\n",
              "      <td>First</td>\n",
              "      <td>2.0</td>\n",
              "      <td>female</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Name PClass   Age     Sex  Survived  SexCode\n",
              "0  Allen, Miss Elisabeth Walton  First  29.0  female         1        1\n",
              "1   Allison, Miss Helen Loraine  First   2.0  female         0        1"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create URL\n",
        "url = 'https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/titanic.csv'\n",
        "# Load data\n",
        "dataframe = pd.read_csv(url)\n",
        "# Replace values, show two rows\n",
        "dataframe.replace(r\"1st\", \"First\", regex=True).head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN9CcWZssCff"
      },
      "source": [
        "# 3.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnTSgGCvsCff",
        "outputId": "b08d3482-7803-47bd-b6e9-90b7616ed17f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "\n",
              "   Parch     Ticket     Fare Cabin Embarked  \n",
              "0      0  A/5 21171   7.2500   NaN        S  \n",
              "1      0   PC 17599  71.2833   C85        C  "
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load library\n",
        "import pandas as pd\n",
        "# Create URL\n",
        "url = 'titanic.csv'\n",
        "# Load data\n",
        "dataframe = pd.read_csv(url)\n",
        "# Rename column, show two rows\n",
        "dataframe.rename(columns={'PClass': 'Passenger Class'}).head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u4x7j0usCff"
      },
      "source": [
        "# Chương 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ESfAxv9sCfg"
      },
      "source": [
        "# 4.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MIKuqzesCfg",
        "outputId": "e155c8a2-c81f-4670-ef11-b6ef7a5ce6cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        ],\n",
              "       [0.28571429],\n",
              "       [0.35714286],\n",
              "       [0.42857143],\n",
              "       [1.        ]])"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Create feature\n",
        "feature = np.array([[-500.5],\n",
        "                    [-100.1],\n",
        "                    [0],\n",
        "                    [100.1],\n",
        "                    [900.9]])\n",
        "\n",
        "# Create scaler\n",
        "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "# Scale feature\n",
        "scaled_feature = minmax_scale.fit_transform(feature)\n",
        "\n",
        "# Show feature\n",
        "scaled_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z05cH3yasCfg",
        "outputId": "ce964baf-c9d1-4186-880c-44e34472c4bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
          ]
        }
      ],
      "source": [
        "print(minmax_scale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdOGN_agsCfh"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDUayUfdsCfh"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KtPs4lcsCfh"
      },
      "source": [
        "# 4.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CREJnjsHsCfh"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhNrYmE8sCfh"
      },
      "outputs": [],
      "source": [
        "# Create feature\n",
        "x = np.array([[-1000.1],\n",
        "              [-200.2],\n",
        "              [500.5],\n",
        "              [600.6],\n",
        "              [9000.9]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv_fU0QDsCfi"
      },
      "outputs": [],
      "source": [
        "# Create scaler\n",
        "scaler = preprocessing.StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXWkdKDhsCfi"
      },
      "outputs": [],
      "source": [
        "# Transform the feature\n",
        "standardized = scaler.fit_transform(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4nlfiLPsCfi",
        "outputId": "ca978036-4a53-4212-8a98-f9aa89e028fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.76058269],\n",
              "       [-0.54177196],\n",
              "       [-0.35009716],\n",
              "       [-0.32271504],\n",
              "       [ 1.97516685]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show feature\n",
        "standardized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzPbZGEisCfj"
      },
      "source": [
        "# 4.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oA-Vu7FsCfj"
      },
      "outputs": [],
      "source": [
        "# Load library\n",
        "import numpy as np\n",
        "# Create feature matrix\n",
        "features = np.array([[1.1, 11.1],\n",
        "[2.2, 22.2],\n",
        "[3.3, 33.3],\n",
        "[4.4, 44.4],\n",
        "[np.nan, 55]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoIXRh3vsCfj",
        "outputId": "3d1691f9-182c-45c9-dc58-66e38e84f5bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.1, 11.1],\n",
              "       [ 2.2, 22.2],\n",
              "       [ 3.3, 33.3],\n",
              "       [ 4.4, 44.4]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Keep only observations that are not (denoted by ~) missing\n",
        "features[~np.isnan(features).any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXUuav9CsCfj",
        "outputId": "dff88559-ed63-4dbd-a25d-290dcb7ad360"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.02985</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.08829</td>\n",
              "      <td>12.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.14455</td>\n",
              "      <td>12.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.21124</td>\n",
              "      <td>12.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.17004</td>\n",
              "      <td>12.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.22489</td>\n",
              "      <td>12.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.11747</td>\n",
              "      <td>12.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.09378</td>\n",
              "      <td>12.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.62976</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.63796</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.62739</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.05393</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.78420</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.80271</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.72580</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1.25179</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.85204</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1.23247</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.98843</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.75026</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.84054</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.67191</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.95577</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.77299</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1.00245</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>4.87141</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>15.02340</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>10.23300</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479</th>\n",
              "      <td>14.33370</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>5.82401</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>5.70818</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>5.73116</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>483</th>\n",
              "      <td>2.81838</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>2.37857</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>3.67367</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>5.69175</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>4.83567</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>488</th>\n",
              "      <td>0.15086</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>0.18337</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>0.20746</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>0.10574</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>0.11132</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>0.17331</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>0.27957</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>0.17899</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>0.28960</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>0.26838</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>0.23912</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>0.17783</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>0.22438</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>0.06263</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>0.04527</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>0.06076</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>0.10959</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>0.04741</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>506 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     feature_1  feature_2\n",
              "0      0.00632       18.0\n",
              "1      0.02731        0.0\n",
              "2      0.02729        0.0\n",
              "3      0.03237        0.0\n",
              "4      0.06905        0.0\n",
              "5      0.02985        0.0\n",
              "6      0.08829       12.5\n",
              "7      0.14455       12.5\n",
              "8      0.21124       12.5\n",
              "9      0.17004       12.5\n",
              "10     0.22489       12.5\n",
              "11     0.11747       12.5\n",
              "12     0.09378       12.5\n",
              "13     0.62976        0.0\n",
              "14     0.63796        0.0\n",
              "15     0.62739        0.0\n",
              "16     1.05393        0.0\n",
              "17     0.78420        0.0\n",
              "18     0.80271        0.0\n",
              "19     0.72580        0.0\n",
              "20     1.25179        0.0\n",
              "21     0.85204        0.0\n",
              "22     1.23247        0.0\n",
              "23     0.98843        0.0\n",
              "24     0.75026        0.0\n",
              "25     0.84054        0.0\n",
              "26     0.67191        0.0\n",
              "27     0.95577        0.0\n",
              "28     0.77299        0.0\n",
              "29     1.00245        0.0\n",
              "..         ...        ...\n",
              "476    4.87141        0.0\n",
              "477   15.02340        0.0\n",
              "478   10.23300        0.0\n",
              "479   14.33370        0.0\n",
              "480    5.82401        0.0\n",
              "481    5.70818        0.0\n",
              "482    5.73116        0.0\n",
              "483    2.81838        0.0\n",
              "484    2.37857        0.0\n",
              "485    3.67367        0.0\n",
              "486    5.69175        0.0\n",
              "487    4.83567        0.0\n",
              "488    0.15086        0.0\n",
              "489    0.18337        0.0\n",
              "490    0.20746        0.0\n",
              "491    0.10574        0.0\n",
              "492    0.11132        0.0\n",
              "493    0.17331        0.0\n",
              "494    0.27957        0.0\n",
              "495    0.17899        0.0\n",
              "496    0.28960        0.0\n",
              "497    0.26838        0.0\n",
              "498    0.23912        0.0\n",
              "499    0.17783        0.0\n",
              "500    0.22438        0.0\n",
              "501    0.06263        0.0\n",
              "502    0.04527        0.0\n",
              "503    0.06076        0.0\n",
              "504    0.10959        0.0\n",
              "505    0.04741        0.0\n",
              "\n",
              "[506 rows x 2 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load library\n",
        "import pandas as pd\n",
        "# Load data\n",
        "dataframe = pd.DataFrame(features, columns=[\"feature_1\", \"feature_2\"])\n",
        "# Remove observations with missing values\n",
        "dataframe.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uuw45x-CsCfk"
      },
      "source": [
        "# 4.11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-_7GLVesCfk"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from fancyimpute import KNN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_blobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPTB5GpgsCfk"
      },
      "outputs": [],
      "source": [
        "# Make a simulated feature matrix\n",
        "features, _ = make_blobs(n_samples = 1000,n_features = 2,random_state = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2uZAQNCsCfl"
      },
      "outputs": [],
      "source": [
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "standardized_features = scaler.fit_transform(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF4nOZnysCfl"
      },
      "outputs": [],
      "source": [
        "# Replace the first feature's first value with a missing value\n",
        "true_value = standardized_features[0,0]\n",
        "standardized_features[0,0] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSVO0od2sCfl"
      },
      "outputs": [],
      "source": [
        "# Predict the missing values in the feature matrix\n",
        "features_knn_imputed = KNN(k=5, verbose=0).complete(standardized_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuaMYjO_sCfl",
        "outputId": "b3c5c548-0e20-4295-93a1-790825bdd99b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Value: 0.8730186113995938\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'features_knn_imputed' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-30-05bc405bbe4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Compare true and imputed values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"True Value:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Imputed Value:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_knn_imputed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'features_knn_imputed' is not defined"
          ]
        }
      ],
      "source": [
        "# Compare true and imputed values\n",
        "print(\"True Value:\", true_value)\n",
        "print(\"Imputed Value:\", features_knn_imputed[0,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udUb_E1SsCfm"
      },
      "source": [
        "# Chương 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_aRozLysCfm"
      },
      "source": [
        "# 9.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wz4UVT9sCfn"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vrHY5BMsCfn"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "digits = datasets.load_digits()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxkuJAAXsCfn",
        "outputId": "cd2bc37a-7801-4ea9-e363-da1a751c8a28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
              "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
              "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
              "        ...,\n",
              "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
              "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
              " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
              " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
              " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
              "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
              "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
              "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
              "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
              "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
              "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
              "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
              "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
              "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
              "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
              "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
              "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
              "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
              "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
              "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
              " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttp://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUnrsHAesCfn"
      },
      "outputs": [],
      "source": [
        "# Standardize the feature matrix\n",
        "features = StandardScaler().fit_transform(digits.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PtHjseQsCfo"
      },
      "outputs": [],
      "source": [
        "# Create a PCA that will retain 99% of variance\n",
        "pca = PCA(n_components=0.8, whiten=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8T2d5JWHsCfo"
      },
      "outputs": [],
      "source": [
        "# Conduct PCA\n",
        "features_pca = pca.fit_transform(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_m1KsaksCfo",
        "outputId": "ed46ffeb-c369-4e32-c3d6-94e71995249c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original number of features: 64\n",
            "Reduced number of features: 21\n"
          ]
        }
      ],
      "source": [
        "# Show results\n",
        "print(\"Original number of features:\", features.shape[1])\n",
        "print(\"Reduced number of features:\", features_pca.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKLYmqrNsCfp"
      },
      "source": [
        "# 9.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsmUxUDfsCfp"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.datasets import make_circles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6ME3SPKsCfp"
      },
      "outputs": [],
      "source": [
        "# Create linearly inseparable data\n",
        "features, _ = make_circles(n_samples=1000, random_state=1, noise=0.1, factor=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i20PQvGasCfp"
      },
      "outputs": [],
      "source": [
        "# Apply kernal PCA with radius basis function (RBF) kernel\n",
        "kpca = KernelPCA(kernel=\"rbf\", gamma=15, n_components=1)\n",
        "features_kpca = kpca.fit_transform(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlgQU0GwsCfp",
        "outputId": "6e70b6fe-f452-4a72-c3d7-3ca5f1905382"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original number of features: 2\n",
            "Reduced number of features: 1\n"
          ]
        }
      ],
      "source": [
        "print(\"Original number of features:\", features.shape[1])\n",
        "print(\"Reduced number of features:\", features_kpca.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBpH48NvsCfq"
      },
      "source": [
        "# 9.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vR3DPB0UsCfq"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyO3N4zJsCfq"
      },
      "outputs": [],
      "source": [
        "# Load Iris flower dataset:\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKTu0WfJsCfq",
        "outputId": "2a3f3de7-b4be-494d-f902-cd0430b0a9e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c18BS0MAsCfq",
        "outputId": "b96036b4-9847-4f7f-a3b3-6978ea665c7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(150,)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRgNhS_FsCfr"
      },
      "outputs": [],
      "source": [
        "# Create and run an LDA, then use it to transform the features\n",
        "lda = LinearDiscriminantAnalysis(n_components=1) #Số tính năng loại bỏ : 1\n",
        "features_lda = lda.fit(features, target).transform(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5cOpf88sCfr",
        "outputId": "6d119d3e-6280-4fe3-80f8-d7654ce13f93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original number of features: 4\n",
            "Reduced number of features: 1\n"
          ]
        }
      ],
      "source": [
        "# Print the number of features\n",
        "print(\"Original number of features:\", features.shape[1])\n",
        "print(\"Reduced number of features:\", features_lda.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7dr5A3osCfr",
        "outputId": "67dc07c0-9147-441e-b4aa-eede44fd2649"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.9912126])"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lda.explained_variance_ratio_ #Phần trăm thông tin còn lại"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfMmiioesCfr",
        "outputId": "c288ac93-4427-4ab2-f156-137918b5634f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zomoh4WDsCfs",
        "outputId": "279faa80-b220-47dc-8cc6-3880dbaf74d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeCXkPa0sCfs"
      },
      "source": [
        "# Discussion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXwWieLpsCfs",
        "outputId": "bd4f6dc9-53f5-4fbd-cbac-797f2a12ac1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9912126049653671\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create and run LDA\n",
        "lda = LinearDiscriminantAnalysis(n_components=None)\n",
        "features_lda = lda.fit(features, target)\n",
        "\n",
        "# Create array of explained variance ratios\n",
        "lda_var_ratios = lda.explained_variance_ratio_\n",
        "\n",
        "# Create function\n",
        "def select_n_components(var_ratio, goal_var: float) -> int:\n",
        "    # Set initial variance explained so far\n",
        "    total_variance = 0.0\n",
        "    # Set initial number of features\n",
        "    n_components = 0\n",
        "    # For the explained variance of each feature:\n",
        "    for explained_variance in var_ratio:\n",
        "        # Add the explained variance to the total\n",
        "        total_variance += explained_variance\n",
        "        # Add one to the number of components\n",
        "        n_components += 1\n",
        "        # If we reach our goal level of explained variance\n",
        "        if total_variance >= goal_var:\n",
        "            # End the loop\n",
        "            break\n",
        "    # Return the number of components\n",
        "    return n_components\n",
        "# Run function\n",
        "select_n_components(lda_var_ratios, 0.95) #Phần trăm dữ liệu mong muốn :0,95"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54qBxTbcsCft",
        "outputId": "4e2e561f-3158-448c-c563-c929b3c9ec9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9912126 0.0087874]\n"
          ]
        }
      ],
      "source": [
        "print(lda_var_ratios)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkAiV-88sCft"
      },
      "source": [
        "# 9.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-u5qq7qsCft",
        "outputId": "0ae0e212-9752-4c33-d8f0-1a472c07f5d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original number of features: 64\n",
            "Reduced number of features: 10\n"
          ]
        }
      ],
      "source": [
        "# Load libraries\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn import datasets\n",
        "\n",
        "# Load the data\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# Load feature matrix\n",
        "features = digits.data\n",
        "\n",
        "# Create, fit, and apply NMF\n",
        "nmf = NMF(n_components=10, random_state=1)\n",
        "features_nmf = nmf.fit_transform(features)\n",
        "\n",
        "# Show results\n",
        "print(\"Original number of features:\", features.shape[1])\n",
        "print(\"Reduced number of features:\", features_nmf.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UICeKOowsCft"
      },
      "source": [
        "# Chương 11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9verWxgjsCft"
      },
      "source": [
        "# 11.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsWrl1bssCfu"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from sklearn import datasets\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pATZqaVsCfu",
        "outputId": "efc44048-0081-4afe-bae9-e1d1af68fc8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.964931719428926"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load digits dataset\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# Create features matrix\n",
        "features = digits.data\n",
        "\n",
        "# Create target vector\n",
        "target = digits.target\n",
        "\n",
        "# Create standardizer\n",
        "standardizer = StandardScaler()\n",
        "\n",
        "# Create logistic regression object\n",
        "logit = LogisticRegression()\n",
        "\n",
        "# Create a pipeline that standardizes, then runs logistic regression\n",
        "pipeline = make_pipeline(standardizer, logit)\n",
        "\n",
        "# Create k-Fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "\n",
        "# Conduct k-fold cross-validation\n",
        "cv_results = cross_val_score(pipeline, # Pipeline\n",
        "features, # Feature matrix\n",
        "target, # Target vector\n",
        "cv=kf, # Cross-validation technique\n",
        "scoring=\"accuracy\", # Loss function\n",
        "n_jobs=-1) # Use all CPU scores\n",
        "\n",
        "# Calculate mean\n",
        "cv_results.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5VB4YmYsCfu",
        "outputId": "3f1e08c0-887b-4136-fa03-da90138683f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.97222222, 0.97777778, 0.95555556, 0.95      , 0.95555556,\n",
              "       0.98333333, 0.97777778, 0.96648045, 0.96089385, 0.94972067])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View score for all 10 folds\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jEPHJeesCfv"
      },
      "outputs": [],
      "source": [
        "# Import library\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create training and test sets\n",
        "features_train, features_test, target_train, target_test = train_test_split(\n",
        "features, target, test_size=0.1, random_state=1)\n",
        "\n",
        "# Fit standardizer to training set\n",
        "standardizer.fit(features_train)\n",
        "\n",
        "# Apply to both training and test sets\n",
        "features_train_std = standardizer.transform(features_train)\n",
        "features_test_std = standardizer.transform(features_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znpI6QkKsCfv"
      },
      "outputs": [],
      "source": [
        "# Create a pipeline\n",
        "pipeline = make_pipeline(standardizer, logit)\n",
        "\n",
        "# Do k-fold cross-validation\n",
        "cv_results = cross_val_score(pipeline, # Pipeline\n",
        "features, # Feature matrix\n",
        "target, # Target vector\n",
        "cv=kf, # Cross-validation technique\n",
        "scoring=\"accuracy\", # Loss function\n",
        "n_jobs=-1) # Use all CPU scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEJSCvIOsCfv"
      },
      "source": [
        "# 11.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD3H_YoJsCfv",
        "outputId": "ca35ee26-40ee-44e7-a710-73be5f282673"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-0.001119359203955339"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load libraries\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "boston = load_boston()\n",
        "\n",
        "# Create features\n",
        "features, target = boston.data, boston.target\n",
        "\n",
        "# Make test and training split\n",
        "features_train, features_test, target_train, target_test = train_test_split(\n",
        "features, target, random_state=0)\n",
        "\n",
        "# Create a dummy regressor\n",
        "dummy = DummyRegressor(strategy='mean')\n",
        "\n",
        "# \"Train\" dummy regressor\n",
        "dummy.fit(features_train, target_train)\n",
        "\n",
        "# Get R-squared score\n",
        "dummy.score(features_test, target_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KP5vHCNHsCfw",
        "outputId": "216d94ca-0527-4e4c-f935-3ce3c17bb58c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6354638433202129"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load library\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Train simple linear regression model\n",
        "ols = LinearRegression()\n",
        "ols.fit(features_train, target_train)\n",
        "\n",
        "# Get R-squared score\n",
        "ols.score(features_test, target_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6DzdjKNsCfw",
        "outputId": "188a4747-ce39-449e-9bfb-97d687366e18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-0.06510502029325727"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create dummy regressor that predicts 20's for everything\n",
        "clf = DummyRegressor(strategy='constant', constant=20)\n",
        "clf.fit(features_train, target_train)\n",
        "# Evaluate score\n",
        "clf.score(features_test, target_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBShnrSAsCfx",
        "outputId": "e3f93f67-b8d8-48cd-a85c-a58e9d801c14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.42105263157894735"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "iris = load_iris()\n",
        "\n",
        "# Create target vector and feature matrix\n",
        "features, target = iris.data, iris.target\n",
        "\n",
        "# Split into training and test set\n",
        "features_train, features_test, target_train, target_test = train_test_split(\n",
        "features, target, random_state=0)\n",
        "\n",
        "# Create dummy classifier\n",
        "dummy = DummyClassifier(strategy='uniform', random_state=1)\n",
        "\n",
        "# \"Train\" model\n",
        "dummy.fit(features_train, target_train)\n",
        "\n",
        "# Get accuracy score\n",
        "dummy.score(features_test, target_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g21gwHblsCfx",
        "outputId": "bccf5f4a-6957-44f0-e1a7-4fa55783bb50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method DummyClassifier.fit of DummyClassifier(constant=None, random_state=1, strategy='uniform')>\n"
          ]
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_39zrLyTsCfx"
      },
      "source": [
        "# Chương 12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4oVHQC_sCfx"
      },
      "source": [
        "# 12.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRAz7D2DsCfx"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from sklearn import linear_model, datasets\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Create logistic regression / Tạo hàm hồi quy Logistic\n",
        "logistic = linear_model.LogisticRegression()\n",
        "# Create range of candidate penalty hyperparameter values\n",
        "penalty = ['l1', 'l2']\n",
        "# Create range of candidate regularization hyperparameter values\n",
        "C = np.logspace(0, 4, 10)\n",
        "# Create dictionary hyperparameter candidates\n",
        "hyperparameters = dict(C=C, penalty=penalty)\n",
        "# Create grid search\n",
        "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
        "# Fit grid search\n",
        "best_model = gridsearch.fit(features, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANu7yS69sCfy",
        "outputId": "6058d96d-68c0-4fb4-ea0f-e58fd7196045"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
              "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
              "       3.59381366e+03, 1.00000000e+04])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.logspace(0, 4, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFRgmFa9sCfy",
        "outputId": "68859ede-bfd9-4288-b0e4-7d3aee11fdbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Penalty: l1\n",
            "Best C: 7.742636826811269\n"
          ]
        }
      ],
      "source": [
        "# View best hyperparameters\n",
        "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
        "print('Best C:', best_model.best_estimator_.get_params()['C'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4QVtZ-5sCfy",
        "outputId": "118522dc-3c9e-4bc8-c499-22adc25fae21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predict target vector\n",
        "best_model.predict(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuwVn35WsCfy"
      },
      "source": [
        "# 12.2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8iXJ3nNsCfz"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from scipy.stats import uniform\n",
        "from sklearn import linear_model, datasets\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Create logistic regression\n",
        "logistic = linear_model.LogisticRegression()\n",
        "# Create range of candidate regularization penalty hyperparameter values\n",
        "penalty = ['l1', 'l2']\n",
        "# Create distribution of candidate regularization hyperparameter values\n",
        "C = uniform(loc=0, scale=4)\n",
        "# Create hyperparameter options\n",
        "hyperparameters = dict(C=C, penalty=penalty)\n",
        "# Create randomized search\n",
        "randomizedsearch = RandomizedSearchCV(logistic, hyperparameters, random_state=1, n_iter=100, cv=5, verbose=0,n_jobs=-1)\n",
        "# Fit randomized search\n",
        "best_model = randomizedsearch.fit(features, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtGL19GMsCfz",
        "outputId": "4cd705c9-946f-4409-97c7-ef7e005c99d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.15410693, 3.80848059, 0.37225622, 1.63457498, 0.69171212,\n",
              "       3.37327902, 0.59101231, 0.69404689, 1.43880545, 3.74458844])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define a uniform distribution between 0 and 4, sample 10 values\n",
        "uniform(loc=0, scale=4).rvs(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2M3TmSxsCfz",
        "outputId": "94c90020-a85e-48a8-d697-427866c30e68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Penalty: l1\n",
            "Best C: 1.668088018810296\n"
          ]
        }
      ],
      "source": [
        "# View best hyperparameters\n",
        "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
        "print('Best C:', best_model.best_estimator_.get_params()['C'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oi3dWM_IsCf0",
        "outputId": "d4f487b0-5ca3-42fc-af53-1ff7ee6b22cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
              "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predict target vector\n",
        "best_model.predict(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxq44tL7sCf0"
      },
      "source": [
        "# 12.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXJa7E67sCf0"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "# Set random seed\n",
        "np.random.seed(0)\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Create a pipeline\n",
        "pipe = Pipeline([(\"classifier\", RandomForestClassifier())])\n",
        "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
        "search_space = [{\"classifier\": [LogisticRegression()],\n",
        "                \"classifier__penalty\": ['l1', 'l2'],\n",
        "                \"classifier__C\": np.logspace(0, 4, 10)},\n",
        "                {\"classifier\": [RandomForestClassifier()],\n",
        "                \"classifier__n_estimators\": [10, 100, 1000],\n",
        "                \"classifier__max_features\": [1, 2, 3]}]\n",
        "# Create grid search\n",
        "gridsearch = GridSearchCV(pipe, search_space, cv=5, verbose=0)\n",
        "# Fit grid search\n",
        "best_model = gridsearch.fit(features, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IU0fMagsCf1",
        "outputId": "1107b5b6-7c75-43d6-dc63-9eacbcf8b953"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=7.742636826811269, class_weight=None, dual=False,\n",
              "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
              "          multi_class='warn', n_jobs=None, penalty='l1', random_state=None,\n",
              "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View best model\n",
        "best_model.best_estimator_.get_params()[\"classifier\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fw4-Ff4sCf1"
      },
      "source": [
        "# 12.4 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doZlUYjgsCf1"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Set random seed\n",
        "np.random.seed(0)\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Create a preprocessing object that includes StandardScaler features and PCA/Tạo tiền xử lý cùng chuẩn hóa và PCA\n",
        "preprocess = FeatureUnion([(\"std\", StandardScaler()), (\"pca\", PCA())])\n",
        "# Create a pipeline\n",
        "pipe = Pipeline([(\"preprocess\", preprocess),\n",
        "                (\"classifier\", LogisticRegression())])\n",
        "# Create space of candidate values\n",
        "search_space = [{\"preprocess__pca__n_components\": [1, 2, 3],\n",
        "                \"classifier__penalty\": [\"l1\", \"l2\"],\n",
        "                \"classifier__C\": np.logspace(0, 4, 10)}]\n",
        "# Create grid search\n",
        "clf = GridSearchCV(pipe, search_space, cv=5, verbose=0, n_jobs=-1)\n",
        "# Fit grid search\n",
        "best_model = clf.fit(features, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lu90KlJ_sCf2",
        "outputId": "b1e6b398-2779-43b1-a06b-deae9bd5160f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View best model\n",
        "best_model.best_estimator_.get_params()['preprocess__pca__n_components']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nszi74gLsCf2"
      },
      "source": [
        "# 12.5 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yszZ1LxsCf2"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from sklearn import linear_model, datasets\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixPLRpXvsCf3",
        "outputId": "535d5510-d407-4412-f84c-427cb3ed77a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 2000 candidates, totalling 10000 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed:    0.8s\n",
            "[Parallel(n_jobs=-1)]: Done 8608 tasks      | elapsed:   12.5s\n",
            "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed:   14.7s finished\n"
          ]
        }
      ],
      "source": [
        "# Create logistic regression\n",
        "logistic = linear_model.LogisticRegression()\n",
        "# Create range of candidate regularization penalty hyperparameter values\n",
        "penalty = [\"l1\", \"l2\"]\n",
        "# Create range of candidate values for C\n",
        "C = np.logspace(0, 4, 1000)\n",
        "# Create hyperparameter options\n",
        "hyperparameters = dict(C=C, penalty=penalty)\n",
        "# Create grid search\n",
        "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, n_jobs=-1, verbose=1)\n",
        "# Fit grid search\n",
        "best_model = gridsearch.fit(features, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iI2kPlW0sCf3",
        "outputId": "3eadc319-405d-44b1-a4bf-6225dbcdcbf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 2000 candidates, totalling 10000 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 10000 out of 10000 | elapsed:   59.7s finished\n"
          ]
        }
      ],
      "source": [
        "# Create grid search using one core\n",
        "clf = GridSearchCV(logistic, hyperparameters, cv=5, n_jobs=1, verbose=1)\n",
        "# Fit grid search\n",
        "best_model = clf.fit(features, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R1BEEJGsCf3"
      },
      "source": [
        "# 12.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_kzrh4NsCf3",
        "outputId": "11cfc2e9-f45e-4120-ff39-55d79a9ab83d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegressionCV(Cs=100, class_weight=None, cv='warn', dual=False,\n",
              "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
              "           multi_class='warn', n_jobs=None, penalty='l2',\n",
              "           random_state=None, refit=True, scoring=None, solver='lbfgs',\n",
              "           tol=0.0001, verbose=0)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load libraries\n",
        "from sklearn import linear_model, datasets\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Create cross-validated logistic regression\n",
        "logit = linear_model.LogisticRegressionCV(Cs=100)\n",
        "# Train model\n",
        "logit.fit(features, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj0S1I8jsCf4"
      },
      "source": [
        "# 12.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpFP7QowsCf4",
        "outputId": "1f004a31-50c0-4ea0-cfe0-d935404bf99a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9534313725490197"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from sklearn import linear_model, datasets\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Create logistic regression\n",
        "logistic = linear_model.LogisticRegression()\n",
        "# Create range of 20 candidate values for C\n",
        "C = np.logspace(0, 4, 20)\n",
        "# Create hyperparameter options\n",
        "hyperparameters = dict(C=C)\n",
        "# Create grid search\n",
        "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, n_jobs=-1, verbose=0)\n",
        "# Conduct nested cross-validation and outut the average score\n",
        "cross_val_score(gridsearch, features, target).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhVTsS3HsCf4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF9Tgi_6sCf4"
      },
      "source": [
        "# Chương 13"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz6VvFHHsCf4"
      },
      "source": [
        "# 13.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W18kkVWLsCf5"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import load_boston"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLn_ze2tsCf5"
      },
      "outputs": [],
      "source": [
        "# Load data with only two features\n",
        "boston = load_boston()\n",
        "features = boston.data[:,0:2]\n",
        "target = boston.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcVLpLLRsCf5",
        "outputId": "b7d65997-cc9a-426a-cbee-306102fc2992"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
              "         4.9800e+00],\n",
              "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
              "         9.1400e+00],\n",
              "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
              "         4.0300e+00],\n",
              "        ...,\n",
              "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "         5.6400e+00],\n",
              "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
              "         6.4800e+00],\n",
              "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "         7.8800e+00]]),\n",
              " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
              "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
              "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
              "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
              "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
              "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
              "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
              "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
              "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
              "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
              "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
              "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
              "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
              "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
              "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
              "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
              "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
              "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
              "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
              "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
              "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
              "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
              "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
              "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
              "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
              "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
              "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
              "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
              "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
              "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
              "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
              "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
              "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
              "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
              "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
              "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
              "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
              "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
              "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
              "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
              "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
              "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
              "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
              "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
              "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
              "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
              " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
              "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
              " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
              " 'filename': 'D:\\\\Hocmay\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\boston_house_prices.csv'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "boston"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtlPlzGNsCf5"
      },
      "outputs": [],
      "source": [
        "# Create linear regression\n",
        "regression = LinearRegression() #Tạo hàm hồi quy tuyến tính"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHov6y5usCf6"
      },
      "outputs": [],
      "source": [
        "# Fit the linear regression\n",
        "model = regression.fit(features, target)  #Thêm đối tượng và mục tiêu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY9Z7WyesCf6",
        "outputId": "384e14c2-6fc3-4a1d-934e-52a66a0d14bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22.485628113468223"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View the intercept\n",
        "model.intercept_ #B0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJzwcK5tsCf6",
        "outputId": "cf2e42c8-5101-4259-a690-94969656ba5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.35207832,  0.11610909])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View the feature coefficients\n",
        "model.coef_ #B1  B2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyU_g7UEsCf6",
        "outputId": "35907a13-dd3d-4266-a177-883f03c348f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "24000.0"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# First value in the target vector multiplied by 1000\n",
        "target[0]*1000 #Giá trị nhà đơn vị nghìn $"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kzg0mzvJsCf7",
        "outputId": "36935df7-4c0c-45de-989c-65a8c036506a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "24573.366631705547"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predict the target value of the first observation, multiplied by 1000\n",
        "model.predict(features)[0]*1000 #Dự đoán giá trị nhà"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3u9Q9GyjsCf7",
        "outputId": "de0cded9-a323-4262-e698-dee5244f14c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-352.07831564026765"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# First coefficient multiplied by 1000\n",
        "model.coef_[0]*1000 #Điều này nói lên rằng mỗi tội phạm tính theo đầu người sẽ làm giảm giá căn nhà khoảng $ 350!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZaUNLIesCf7"
      },
      "source": [
        "# 13.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTir7H6isCf7"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import PolynomialFeatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfksP0y8sCf8"
      },
      "outputs": [],
      "source": [
        "# Load data with only two features\n",
        "boston = load_boston()\n",
        "features = boston.data[:,0:2]\n",
        "target = boston.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7dOZu1LsCf8"
      },
      "outputs": [],
      "source": [
        "# Create interaction term\n",
        "interaction = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
        "features_interaction = interaction.fit_transform(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IanfQJRsCf8",
        "outputId": "93201b73-3a54-45eb-93e6-6c7cbef36d11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[6.3200e-03, 1.8000e+01, 1.1376e-01],\n",
              "       [2.7310e-02, 0.0000e+00, 0.0000e+00],\n",
              "       [2.7290e-02, 0.0000e+00, 0.0000e+00],\n",
              "       ...,\n",
              "       [6.0760e-02, 0.0000e+00, 0.0000e+00],\n",
              "       [1.0959e-01, 0.0000e+00, 0.0000e+00],\n",
              "       [4.7410e-02, 0.0000e+00, 0.0000e+00]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features_interaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju4MOuA5sCf8",
        "outputId": "14e5d01f-a4be-44c8-9340-7e1def2645a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'sklearn.preprocessing.data.PolynomialFeatures'>\n"
          ]
        }
      ],
      "source": [
        "print(PolynomialFeatures)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3JCQNOzsCf9"
      },
      "outputs": [],
      "source": [
        "# Create linear regression\n",
        "regression = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6yB_n4IsCf9"
      },
      "outputs": [],
      "source": [
        "# Fit the linear regression\n",
        "model = regression.fit(features_interaction, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hGsnDlKsCf9",
        "outputId": "a72d3687-9d6f-4365-f87a-bda90dc37c0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([6.32e-03, 1.80e+01])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View the feature values for first observation\n",
        "features[0] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqutxcC3sCf9"
      },
      "outputs": [],
      "source": [
        "# Import library\n",
        "import numpy as np\n",
        "# For each observation, multiply the values of the first and second feature\n",
        "#Đối với mỗi quan sát, nhân các giá trị của đặc điểm thứ nhất và thứ hai\n",
        "interaction_term = np.multiply(features[:, 0], features[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rW2S8R4ysCf9",
        "outputId": "1a6183e5-945a-411d-ab51-b19e4b3045fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.11376"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View interaction term for first observation\n",
        "interaction_term[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJpKhgyysCf-",
        "outputId": "9de1c164-5c91-49b5-f411-c5cbc5d51469"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([6.3200e-03, 1.8000e+01, 1.1376e-01])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View the values of the first observation\n",
        "features_interaction[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ksxm5v9rsCf-"
      },
      "source": [
        "# 13.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5ca9TSGsCf-"
      },
      "outputs": [],
      "source": [
        "# Load library\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "# Load data with one feature\n",
        "boston = load_boston()\n",
        "features = boston.data[:,0:1]\n",
        "target = boston.target\n",
        "# Create polynomial features x^2 and x^3 #Tạo đa thức bậc 3\n",
        "polynomial = PolynomialFeatures(degree=3, include_bias=False)\n",
        "features_polynomial = polynomial.fit_transform(features)\n",
        "# Create linear regression\n",
        "regression = LinearRegression() #tạo hàm hồi quy\n",
        "# Fit the linear regression\n",
        "model = regression.fit(features_polynomial, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7Y0Ku84sCf-",
        "outputId": "a4838dc4-0fd0-404d-e2df-ad459660b063"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.00632])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#View first observation\n",
        "features[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVfCh4FLsCf-",
        "outputId": "e851674e-3667-4a26-91b6-7a05e1e6525c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2.52435968e-07])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View first observation raised to the third power, x^3\n",
        "features[0]**3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzJhzmbosCf_",
        "outputId": "f92741cd-3822-4e76-cd7a-45165ee3dc87"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([6.32000000e-03, 3.99424000e-05, 2.52435968e-07])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View the first observation's values for x, x^2, and x^3\n",
        "features_polynomial[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXAFC34_sCf_"
      },
      "source": [
        "# 13.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riWk6ocdsCf_"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Load data\n",
        "boston = load_boston()\n",
        "features = boston.data\n",
        "target = boston.target\n",
        "# Standardize features\n",
        "scaler = StandardScaler() #chuẩn hóa dữ liệu\n",
        "features_standardized = scaler.fit_transform(features)\n",
        "# Create ridge regression with an alpha value\n",
        "regression = Ridge(alpha=0.5) #hệ số alpha\n",
        "# Fit the linear regression\n",
        "model = regression.fit(features_standardized, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-Xr-idYsCgA",
        "outputId": "74bd3c11-29cf-45a4-91fb-43f8b58f717b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.91987132,  1.06646104,  0.11738487,  0.68512693, -2.02901013,\n",
              "        2.68275376,  0.01315848, -3.07733968,  2.59153764, -2.0105579 ,\n",
              "       -2.05238455,  0.84884839, -3.73066646])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load library\n",
        "from sklearn.linear_model import RidgeCV\n",
        "# Create ridge regression with three alpha values\n",
        "regr_cv = RidgeCV(alphas=[0.1, 1.0, 10.0])\n",
        "# Fit the linear regression / Gán giá trị vào hàm hồi quy tuyến tính\n",
        "model_cv = regr_cv.fit(features_standardized, target)\n",
        "# View coefficients\n",
        "model_cv.coef_ #các hệ số"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ge4WiiJsCgA"
      },
      "source": [
        "# 13.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92P4DYBesCgA"
      },
      "outputs": [],
      "source": [
        "# Load library\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Load data\n",
        "boston = load_boston()\n",
        "features = boston.data\n",
        "target = boston.target\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "features_standardized = scaler.fit_transform(features)\n",
        "# Create lasso regression with alpha value\n",
        "regression = Lasso(alpha=0.5) #tạo hàm hồi quy Lasso với alpha = 0.5\n",
        "# Fit the linear regression\n",
        "model = regression.fit(features_standardized, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OWBoGc9sCgA",
        "outputId": "d99f534b-6208-4bf4-97ed-95893f25d00c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.11526463,  0.        , -0.        ,  0.39707879, -0.        ,\n",
              "        2.97425861, -0.        , -0.17056942, -0.        , -0.        ,\n",
              "       -1.59844856,  0.54313871, -3.66614361])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View coefficients\n",
        "model.coef_ #các hệ số"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LJbMycAsCgB",
        "outputId": "7b0d03ae-1dc1-441e-96c5-7bba1d4d36a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.,  0., -0.,  0., -0.,  0., -0.,  0., -0., -0., -0.,  0., -0.])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create lasso regression with a high alpha\n",
        "regression_a10 = Lasso(alpha=10) #tạo hàm hồi quy Lasso với alpha = 10\n",
        "model_a10 = regression_a10.fit(features_standardized, target)\n",
        "model_a10.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXC8WagesCgB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBTkpc4TsCgB"
      },
      "source": [
        "# Chương 14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqZwLwkgsCgB"
      },
      "source": [
        "# 14.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gD2X4hu2sCgB"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUitnLEFsCgB"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Create decision tree classifier object\n",
        "decisiontree = DecisionTreeClassifier(random_state=0)\n",
        "# Train model\n",
        "model = decisiontree.fit(features, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQQnepdmsCgB",
        "outputId": "6a3f56a4-abc2-468c-9941-7d7e8ab3db0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make new observation\n",
        "observation = [[ 5, 4, 3, 2]]\n",
        "# Predict observation's class\n",
        "model.predict(observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7JOo1FRsCgC",
        "outputId": "f0703393-c0fe-439a-d298-8108ea45c83d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 1., 0.]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View predicted class probabilities for the three classes\n",
        "model.predict_proba(observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ljf-oWSisCgC"
      },
      "outputs": [],
      "source": [
        "# Create decision tree classifier object using entropy\n",
        "decisiontree_entropy = DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lVUpv2wsCgC"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "model_entropy = decisiontree_entropy.fit(features, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ1mWW3osCgC"
      },
      "source": [
        "# 14.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PZ2gC5psCgC"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn import datasets\n",
        "# Load data with only two features\n",
        "boston = datasets.load_boston()\n",
        "features = boston.data[:,0:2]\n",
        "target = boston.target\n",
        "# Create decision tree classifier object\n",
        "decisiontree = DecisionTreeRegressor(random_state=0)\n",
        "# Train model\n",
        "model = decisiontree.fit(features, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REYITZrJsCgD",
        "outputId": "8fd6936a-8e01-438a-dd9e-5b7a94de823b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([33.])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make new observation\n",
        "observation = [[0.02, 16]]\n",
        "# Predict observation's value\n",
        "model.predict(observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyzozC1fsCgD",
        "outputId": "eab64119-b41a-41ae-8e08-ad4022354ca1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DecisionTreeRegressor(criterion='mae', max_depth=None, max_features=None,\n",
            "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "           min_impurity_split=None, min_samples_leaf=1,\n",
            "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "           presort=False, random_state=0, splitter='best')\n"
          ]
        }
      ],
      "source": [
        "# Create decision tree classifier object using entropy\n",
        "decisiontree_mae = DecisionTreeRegressor(criterion=\"mae\", random_state=0)\n",
        "# Train model\n",
        "model_mae = decisiontree_mae.fit(features, target)\n",
        "print(model_mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0giCxBbvsCgD"
      },
      "source": [
        "# 14.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MADk8ohtsCgD",
        "outputId": "fa78ff16-3a2c-4e63-b6cd-2ad703e9433e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydotplus in d:\\hocmay\\lib\\site-packages (2.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.1 in d:\\hocmay\\lib\\site-packages (from pydotplus) (2.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pydotplus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLU050posCgD",
        "outputId": "fa50bd60-afbf-406d-da2d-fa99601bf26f"
      },
      "outputs": [
        {
          "ename": "InvocationException",
          "evalue": "GraphViz's executables not found",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-3-844bcce02448>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Show graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mD:\\Hocmay\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, prog)\u001b[0m\n\u001b[0;32m   1795\u001b[0m             self.__setattr__(\n\u001b[0;32m   1796\u001b[0m                 \u001b[1;34m'create_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1797\u001b[1;33m                 \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1798\u001b[0m             )\n\u001b[0;32m   1799\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'create_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Hocmay\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1958\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[1;32m-> 1960\u001b[1;33m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1962\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found"
          ]
        }
      ],
      "source": [
        "# Load libraries\n",
        "import pydotplus\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import datasets\n",
        "from IPython.display import Image\n",
        "from sklearn import tree\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Create decision tree classifier object\n",
        "decisiontree = DecisionTreeClassifier(random_state=0)\n",
        "# Train model\n",
        "model = decisiontree.fit(features, target)\n",
        "# Create DOT data\n",
        "dot_data = tree.export_graphviz(decisiontree,\n",
        "out_file=None,\n",
        "feature_names=iris.feature_names,\n",
        "class_names=iris.target_names)\n",
        "# Draw graph\n",
        "graph = pydotplus.graph_from_dot_data(dot_data)\n",
        "# Show graph\n",
        "Image(graph.create_png())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cS0mFSLsCgE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSoer-P1sCgE"
      },
      "source": [
        "# 14.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkdJI2vCsCgE"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import datasets\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Create random forest classifier object\n",
        "randomforest = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
        "# Train model\n",
        "model = randomforest.fit(features, target)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5U_rfvdVsCgE",
        "outputId": "b8e21d63-1268-4355-ac8c-55b2596a862a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Make new observation\n",
        "observation = [[ 5, 4, 3, 2]]\n",
        "# Predict observation's class\n",
        "model.predict(observation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhYs-w0isCgE"
      },
      "source": [
        "# Chương 15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfuukQBBsCgE"
      },
      "source": [
        "# 15.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVsJeewRsCgE",
        "outputId": "d06d17b5-839a-4335-e034-a44ff052b3c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[1.03800476, 0.55861082, 1.10378283, 1.18556721],\n",
              "        [0.79566902, 0.32841405, 0.76275827, 1.05393502]]])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "# Create standardizer / chuẩn hóa\n",
        "standardizer = StandardScaler()\n",
        "# Standardize features\n",
        "features_standardized = standardizer.fit_transform(features)\n",
        "# Two nearest neighbors / 2 giá trị gần nhất\n",
        "nearest_neighbors = NearestNeighbors(n_neighbors=2).fit(features_standardized)\n",
        "# Create an observation/Tạo quan sát \n",
        "new_observation = [ 1, 1, 1, 1]\n",
        "# Find distances and indices of the observation's nearest neighbors / Tìm khoảng cách và chỉ số của các đối tượng gần nhất đã quan sát\n",
        "distances, indices = nearest_neighbors.kneighbors([new_observation])\n",
        "# View the nearest neighbors\n",
        "features_standardized[indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8Wp5jnJsCgF"
      },
      "outputs": [],
      "source": [
        "#Find two nearest neighbors based on euclidean distance / Tìm 2 đối tượng gần nhất dựa vào khoảng cách Euclide\n",
        "nearestneighbors_euclidean = NearestNeighbors(\n",
        "n_neighbors=2, metric='euclidean').fit(features_standardized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwB2z_gqsCgF",
        "outputId": "a75bc22b-57f4-4c4e-b1a0-27c2f85567ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.49140089, 0.74294782]])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View distances\n",
        "distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSs-vRwFsCgF",
        "outputId": "a17e7282-6e45-40da-994b-5476c2b8c977"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find each observation's three nearest neighbors\n",
        "# based on euclidean distance (including itself)\n",
        "nearestneighbors_euclidean = NearestNeighbors(\n",
        "n_neighbors=3, metric=\"euclidean\").fit(features_standardized)\n",
        "# List of lists indicating each observation's 3 nearest neighbors\n",
        "# (including itself)\n",
        "nearest_neighbors_with_self = nearestneighbors_euclidean.kneighbors_graph(\n",
        "features_standardized).toarray()\n",
        "# Remove 1's marking an observation is a nearest neighbor to itself\n",
        "for i, x in enumerate(nearest_neighbors_with_self):\n",
        "    x[i] = 0\n",
        "# View first observation's two nearest neighbors\n",
        "nearest_neighbors_with_self[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkE-Ky8UsCgF"
      },
      "source": [
        "# 15.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4h4FWtkNsCgF",
        "outputId": "3c18f735-59ec-4a15-9760-ff85a089b37b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load libraries\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import datasets\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "# Create standardizer\n",
        "standardizer = StandardScaler()\n",
        "# Standardize features\n",
        "X_std = standardizer.fit_transform(X)\n",
        "# Train a KNN classifier with 5 neighbors / tạo train KNN với 5 đối tượng gần nhất\n",
        "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1).fit(X_std, y)\n",
        "# Create two observations / Tạo 2 quan sát mới\n",
        "new_observations = [[ 0.75, 0.75, 0.75, 0.75],\n",
        "[ 1, 1, 1, 1]]\n",
        "# Predict the class of two observations\n",
        "knn.predict(new_observations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRzIBV-ssCgF",
        "outputId": "9ec6306d-fcb2-42ae-f126-d339e868a7f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0. , 0.6, 0.4],\n",
              "       [0. , 0. , 1. ]])"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View probability each observation is one of three classes\n",
        "knn.predict_proba(new_observations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYOqS9InsCgG"
      },
      "source": [
        "# 15.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u84rr0ZJsCgG"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Create standardizer\n",
        "standardizer = StandardScaler()\n",
        "# Standardize features\n",
        "features_standardized = standardizer.fit_transform(features)\n",
        "# Create a KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
        "# Create a pipeline\n",
        "pipe = Pipeline([(\"standardizer\", standardizer), (\"knn\", knn)])\n",
        "# Create space of candidate values\n",
        "search_space = [{\"knn__n_neighbors\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n",
        "# Create grid search / tạo lưới tìm kiếm\n",
        "classifier = GridSearchCV(\n",
        "pipe, search_space, cv=5, verbose=0).fit(features_standardized, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9sP9aknsCgG",
        "outputId": "b45af552-5b4c-4356-f91d-10b2878c8d66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Best neighborhood size (k)\n",
        "classifier.best_estimator_.get_params()[\"knn__n_neighbors\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waonytWhsCgG"
      },
      "source": [
        "# 15.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDrTr75osCgG",
        "outputId": "97a07a39-f600-4318-d279-a151c90db19c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load libraries\n",
        "from sklearn.neighbors import RadiusNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import datasets\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Create standardizer\n",
        "standardizer = StandardScaler()\n",
        "# Standardize features\n",
        "features_standardized = standardizer.fit_transform(features)\n",
        "# Train a radius neighbors classifier / đối tượng trong bán kính giá trị 0.5\n",
        "rnn = RadiusNeighborsClassifier(\n",
        "radius=.5, n_jobs=-1).fit(features_standardized, target)\n",
        "# Create two observations\n",
        "new_observations = [[ 1, 1, 1, 1]]\n",
        "# Predict the class of two observations\n",
        "rnn.predict(new_observations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZnmG4XUsCgG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WItYBU0ZsCgH"
      },
      "source": [
        "# Chương 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpiuIfTJsCgH"
      },
      "source": [
        "# 16.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qasir8ufsCgH"
      },
      "outputs": [],
      "source": [
        "# Load libraries / Tạo thư viện\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Load data with only two classes / lấy dữ liệu chỉ với 2 lớp\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data[:100,:]\n",
        "target = iris.target[:100]\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "features_standardized = scaler.fit_transform(features)\n",
        "# Create logistic regression object / tạo logictic cho đối tượng hồi quy\n",
        "logistic_regression = LogisticRegression(random_state=0)\n",
        "# Train model\n",
        "model = logistic_regression.fit(features_standardized, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyTx2vxjsCgH",
        "outputId": "278e4b70-990d-4cf1-891e-7725c4a7ffbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create new observation / Tạo một biến quan sát\n",
        "new_observation = [[.5, .5, .5, .5]]\n",
        "# Predict class / dự đoán lớp\n",
        "model.predict(new_observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLBV43QBsCgH",
        "outputId": "b9499a88-69da-418e-8a76-867d6d7a88e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.18944274, 0.81055726]])"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View predicted probabilities / xác xuất dự đoán có thể\n",
        "model.predict_proba(new_observation) #Xác xuất lớp 0 và 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbiXy-rcsCgH"
      },
      "source": [
        "# 16.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nnu38D5RsCgH"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "features_standardized = scaler.fit_transform(features)\n",
        "# Create one-vs-rest logistic regression object / tạo one-vs-rest logistic cho đối tượng hồi quy \n",
        "logistic_regression = LogisticRegression(random_state=0, multi_class=\"ovr\")\n",
        "# Train model\n",
        "model = logistic_regression.fit(features_standardized, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsMtqXx3sCgI"
      },
      "source": [
        "# 16.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8p57HFHsCgI"
      },
      "outputs": [],
      "source": [
        "#Load libraries\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "features_standardized = scaler.fit_transform(features)\n",
        "# Create decision tree classifier object\n",
        "logistic_regression = LogisticRegressionCV(\n",
        "penalty='l2', Cs=10, random_state=0, n_jobs=-1)\n",
        "# Train model\n",
        "model = logistic_regression.fit(features_standardized, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFn-5lMQsCgI"
      },
      "source": [
        "# 16.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxD3aU24sCgI"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "features_standardized = scaler.fit_transform(features)\n",
        "# Create logistic regression object\n",
        "logistic_regression = LogisticRegression(random_state=0, solver=\"sag\")\n",
        "# Train model\n",
        "model = logistic_regression.fit(features_standardized, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gYPbGPtsCgI"
      },
      "source": [
        "# 16.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RUg40SpsCgI"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Make class highly imbalanced by removing first 40 observations / tạo một lớp rất không cân bằng bằng cách xóa đi 40 đối tượng quan sát\n",
        "features = features[40:,:]\n",
        "target = target[40:]\n",
        "# Create target vector indicating if class 0, otherwise 1 / tạo một vector cho biết nếu lớp 0,\n",
        "target = np.where((target == 0), 0, 1)\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "features_standardized = scaler.fit_transform(features)\n",
        "# Create decision tree classifier object\n",
        "logistic_regression = LogisticRegression(random_state=0, class_weight=\"balanced\")\n",
        "# Train model\n",
        "model = logistic_regression.fit(features_standardized, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDXL4hJHsCgI"
      },
      "source": [
        "# Chương 17"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH6RKbBvsCgI"
      },
      "source": [
        "# 17.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17EcmKj1sCgJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZGIrjULsCgJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBW1ta0GsCgJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AR3Eti94sCgJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J66KvP_rsCgK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiAsN1aFsCgK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miWoxd29sCgK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkVV6XeHsCgK"
      },
      "source": [
        "# Chương 18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzBklc2ksCgK"
      },
      "source": [
        "# 18.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSK3tBLysCgK"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Create Gaussian Naive Bayes object\n",
        "classifer = GaussianNB()\n",
        "# Train model\n",
        "model = classifer.fit(features, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlM9jZIbsCgK",
        "outputId": "ceaa3b8c-3334-4994-a696-39e1505ecad6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create new observation\n",
        "new_observation = [[ 4, 4, 4, 0.4]]\n",
        "# Predict class\n",
        "model.predict(new_observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3-NPsqBsCgK"
      },
      "outputs": [],
      "source": [
        "# Create Gaussian Naive Bayes object with prior probabilities of each class\n",
        "clf = GaussianNB(priors=[0.25, 0.25, 0.5])\n",
        "# Train model\n",
        "model = classifer.fit(features, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsFTSiMIsCgK"
      },
      "source": [
        "# 18.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbGcgZfXsCgK"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Create text\n",
        "text_data = np.array(['I love Brazil. Brazil!',\n",
        "                    'Brazil is best',\n",
        "                    'Germany beats both'])\n",
        "# Create bag of words\n",
        "count = CountVectorizer()\n",
        "bag_of_words = count.fit_transform(text_data)\n",
        "# Create feature matrix\n",
        "features = bag_of_words.toarray()\n",
        "# Create target vector\n",
        "target = np.array([0,0,1])\n",
        "# Create multinomial naive Bayes object with prior probabilities of each class\n",
        "classifer = MultinomialNB(class_prior=[0.25, 0.5])\n",
        "# Train model\n",
        "model = classifer.fit(features, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QFMPWZKsCgL",
        "outputId": "f052d32e-079f-4f35-8848-64d213ead317"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create new observation\n",
        "new_observation = [[0, 0, 0, 1, 0, 1, 0]]\n",
        "# Predict new observation's class\n",
        "model.predict(new_observation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-EceKLosCgL"
      },
      "source": [
        "# 18.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EBFaUFosCgL"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "# Create three binary features\n",
        "features = np.random.randint(2, size=(100, 3))\n",
        "# Create a binary target vector\n",
        "target = np.random.randint(2, size=(100, 1)).ravel()\n",
        "# Create Bernoulli Naive Bayes object with prior probabilities of each class\n",
        "classifer = BernoulliNB(class_prior=[0.25, 0.5])\n",
        "# Train model\n",
        "model = classifer.fit(features, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQL7vVN0sCgL"
      },
      "source": [
        "# 18.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCz59-jCsCgL",
        "outputId": "33d4deef-c7c3-46af-dd64-9b079951b65c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.31859969, 0.63663466, 0.04476565]])"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Create Gaussian Naive Bayes object\n",
        "classifer = GaussianNB()\n",
        "# Create calibrated cross-validation with sigmoid calibration\n",
        "classifer_sigmoid = CalibratedClassifierCV(classifer, cv=2, method='sigmoid')\n",
        "# Calibrate probabilities\n",
        "classifer_sigmoid.fit(features, target)\n",
        "# Create new observation\n",
        "new_observation = [[ 2.6, 2.6, 2.6, 0.4]]\n",
        "# View calibrated probabilities\n",
        "classifer_sigmoid.predict_proba(new_observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEB7Cpp-sCgL",
        "outputId": "2634af82-827b-411e-e545-2a1ca8f65f06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2.31548432e-04, 9.99768128e-01, 3.23532277e-07]])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train a Gaussian naive Bayes then predict class probabilities\n",
        "classifer.fit(features, target).predict_proba(new_observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrFQqvWSsCgL",
        "outputId": "6e7eace9-0d6a-4900-e0f7-30c8ef0bf03a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.31859969, 0.63663466, 0.04476565]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View calibrated probabilities\n",
        "classifer_sigmoid.predict_proba(new_observation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkPU0TbusCgM"
      },
      "source": [
        "# Chương 19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpbXEVxxsCgM"
      },
      "source": [
        "# 19.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhRzzSYEsCgM"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "features_std = scaler.fit_transform(features)\n",
        "# Create k-mean object\n",
        "cluster = KMeans(n_clusters=3, random_state=0, n_jobs=-1) #chia thành 3 nhóm có 3 trọng tâm, đối tượng lấy cố định,\n",
        "# Train model\n",
        "model = cluster.fit(features_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYhcL9hVsCgM",
        "outputId": "ac3a97b4-28ed-4c7d-80ae-b554739b17fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
              "       0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2,\n",
              "       2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2,\n",
              "       2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View predict class\n",
        "model.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDnPfyFysCgM",
        "outputId": "be5c9919-3056-4741-b47f-fefa52bcfc93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View true class\n",
        "iris.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cj57Dz4vsCgM",
        "outputId": "61e3ff0c-4361-43c5-ecd2-173e36a7a34c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create new observation\n",
        "new_observation = [[0.8, 0.8, 0.8, 0.8]]\n",
        "# Predict observation's cluster\n",
        "model.predict(new_observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQPNcXlYsCgM",
        "outputId": "fe33cc69-1564-440e-d56b-aa361f1868d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.05021989, -0.88337647,  0.34773781,  0.2815273 ],\n",
              "       [-1.01457897,  0.85326268, -1.30498732, -1.25489349],\n",
              "       [ 1.13597027,  0.08842168,  0.99615451,  1.01752612]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View cluster centers\n",
        "model.cluster_centers_ #3 trọng tâm, mỗi trọng tâm có 4 thuộc tính"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i7EVzkmsCgM"
      },
      "source": [
        "# 19.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuepbpsEsCgM"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "features_std = scaler.fit_transform(features)\n",
        "# Create k-mean object\n",
        "cluster = MiniBatchKMeans(n_clusters=3, random_state=0, batch_size=100)\n",
        "# Train model\n",
        "model = cluster.fit(features_std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xzfTE7tsCgN"
      },
      "source": [
        "# 19.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQUUqDLDsCgN"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import MeanShift\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "features_std = scaler.fit_transform(features)\n",
        "# Create meanshift object\n",
        "cluster = MeanShift(n_jobs=-1)\n",
        "# Train model\n",
        "model = cluster.fit(features_std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkfkXCoSsCgN"
      },
      "source": [
        "# 19.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9s_1TpWsCgN"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "features_std = scaler.fit_transform(features)\n",
        "# Create meanshift object\n",
        "cluster = DBSCAN(n_jobs=-1)\n",
        "# Train model\n",
        "model = cluster.fit(features_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_0Pen4isCgN",
        "outputId": "f7abf691-e594-4172-aa61-2fc3009cbe89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1,\n",
              "        0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
              "        1,  1,  1,  1,  1, -1, -1,  1, -1, -1,  1, -1,  1,  1,  1,  1,  1,\n",
              "       -1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "       -1,  1, -1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1, -1,  1,\n",
              "        1,  1,  1, -1, -1, -1, -1, -1,  1,  1,  1,  1, -1,  1,  1, -1, -1,\n",
              "       -1,  1,  1, -1,  1,  1, -1,  1,  1,  1, -1, -1, -1,  1,  1,  1, -1,\n",
              "       -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1],\n",
              "      dtype=int64)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show cluster membership\n",
        "model.labels_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41xtl93AsCgN"
      },
      "source": [
        "# 19.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGLEU1YusCgN"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "features_std = scaler.fit_transform(features)\n",
        "# Create meanshift object\n",
        "cluster = AgglomerativeClustering(n_clusters=3) #Tạo meanshift với 3 trọng tâm\n",
        "# Train model\n",
        "model = cluster.fit(features_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Rxp8L12sCgN",
        "outputId": "c6ffd2ee-0329-400d-d852-e09c782a5495"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0,\n",
              "       2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 2,\n",
              "       2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show cluster membership\n",
        "model.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAqdrsyNsCgN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Học-máy (1).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}